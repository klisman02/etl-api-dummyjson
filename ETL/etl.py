# -*- coding: utf-8 -*-
"""etl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xMpoMOS_D6Ew23QJ7UsGPLrFn8rg59fy
"""

import requests
import pandas as pd
import json
import os

def extract_data(endpoint):
    response = requests.get(endpoint)
    if response.status_code == 200:
        return response.json()
    else:
        print(f'Erro ao extrair os dados da API: {response.status_code}')
        return None


# ---------------- LOAD ----------------
def load_data(users, path):
    # cria a pasta se não existir
    os.makedirs(path, exist_ok=True)

    for user in users:
        user_id = user["id"]
        file_path = f"{path}/data_user_{user_id}.json"

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(user, f, indent=4, ensure_ascii=False)



# ---------------- PIPELINE ----------------
endpoint_user = "https://dummyjson.com/users"


data_users = extract_data(endpoint_user)

if data_users:
    load_data(data_users["users"], "./users")
    print("Dados carregados com sucesso!")
else:
    print("Falha na extração dos dados.")
    
    
# ---------------- TRANSFORM ----------------
def transform_data(path):
    all_files = os.listdir(path)
    all_data = []

    for file_name in all_files:
        file_path = os.path.join(path, file_name)
        with open(file_path, "r", encoding="utf-8") as f:
            user_data = json.load(f)
            all_data.append(user_data)

    df = pd.DataFrame(all_data)

    # Exemplo de transformação: selecionar colunas específicas
    df_transformed = df[["id", "firstName", "lastName", "email", "age"]]  

    return df_transformed
  
df_users = transform_data("./users")
print(df_users.head())

